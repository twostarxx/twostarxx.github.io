<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="成本函数(Cost Function)$$J(\theta_0,\theta1) = \frac{1}{2m}\sum{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$$m$ :  Number of training examples.$x$ : input.$y$ : output.Parameters: $\theta_0$, $\theta_1$. 以下为MAT">
<meta property="og:type" content="article">
<meta property="og:title" content="Cost Function的原理及实现(Python, Matlab)">
<meta property="og:url" content="http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/index.html">
<meta property="og:site_name" content="twostarxx">
<meta property="og:description" content="成本函数(Cost Function)$$J(\theta_0,\theta1) = \frac{1}{2m}\sum{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$$m$ :  Number of training examples.$x$ : input.$y$ : output.Parameters: $\theta_0$, $\theta_1$. 以下为MAT">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2017-11-17T16:41:21.939Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cost Function的原理及实现(Python, Matlab)">
<meta name="twitter:description" content="成本函数(Cost Function)$$J(\theta_0,\theta1) = \frac{1}{2m}\sum{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$$m$ :  Number of training examples.$x$ : input.$y$ : output.Parameters: $\theta_0$, $\theta_1$. 以下为MAT">
    
    
        
          
              <link rel="shortcut icon" href="/">
          
        
        
          
            <link rel="icon" type="image/png" href="/" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/">
          
        
    
    <!-- title -->
    <title>Cost Function的原理及实现(Python, Matlab)</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- rss -->
    
    
</head>

<body>
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fa fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fa fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="http://github.com/twostarxx">Projects</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        
        <li><a class="icon" href="/2017/10/24/Collections-sort-List-T-list-Comparator-super-T-c-源代码分析/"><i class="fa fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fa fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/"><i class="fa fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&text=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&is_video=false&description=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Cost Function的原理及实现(Python, Matlab)&body=Check out this article: http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/"><i class="fa fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&name=Cost Function的原理及实现(Python, Matlab)&description="><i class="fa fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#成本函数-Cost-Function"><span class="toc-number">1.</span> <span class="toc-text">成本函数(Cost Function)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度下降法-Gradient-Descent"><span class="toc-number">2.</span> <span class="toc-text">梯度下降法(Gradient Descent)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归中的梯度下降公式"><span class="toc-number">3.</span> <span class="toc-text">线性回归中的梯度下降公式</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index width mx-auto px2 my4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Cost Function的原理及实现(Python, Matlab)
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">twostarxx</span>
      </span>
      
    <div class="postdate">
        <time datetime="2017-11-17T16:31:00.000Z" itemprop="datePublished">2017-11-18</time>
    </div>


      

    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h2 id="成本函数-Cost-Function"><a href="#成本函数-Cost-Function" class="headerlink" title="成本函数(Cost Function)"></a>成本函数(Cost Function)</h2><p>$$J(\theta_0,\theta<em>1) = \frac{1}{2m}\sum</em>{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$<br>$m$ :  Number of training examples.<br>$x$ : input.<br>$y$ : output.<br>Parameters: $\theta_0$, $\theta_1$.</p>
<p>以下为MATLAB实现方式：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">J</span> = <span class="title">computeCost</span><span class="params">(X, y, theta)</span></span></div><div class="line">	<span class="comment">%COMPUTECOST Compute cost for linear regression</span></div><div class="line">	<span class="comment">%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the parameter for linear regression to fit the data points in X and y</span></div><div class="line">	m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></div><div class="line">	J = <span class="number">0</span>;</div><div class="line">	J = sum((X * theta - y) .^<span class="number">2</span>) / <span class="number">2</span> / m;</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>以下为Python实现方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeCost</span><span class="params">(X, y, theta)</span>:</span></div><div class="line">    <span class="string">"""Cost Functions</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    X : np.ndarray, like (49 * 2)</span></div><div class="line"><span class="string">    y : np.ndarray, like (49 * 1)</span></div><div class="line"><span class="string">    theta : np.ndarray, like (2 * 1)</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    J : float, cost</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    """</span></div><div class="line">    y = np.transpose(y)</div><div class="line">    J = sum((np.dot(X, theta) - y.reshape(len(y),<span class="number">1</span>)) **<span class="number">2</span>) / <span class="number">2.0</span> / len(y)</div><div class="line">    <span class="comment"># np.dot(A, B) 矩阵乘积，A * B 矩阵点乘</span></div><div class="line">    <span class="comment"># pow(A, 2) 多次乘积，**n 点次方</span></div><div class="line">    <span class="keyword">return</span> J</div></pre></td></tr></table></figure>
<p>注意：np中点乘和矩阵乘积，点次方与多次乘积的区别，与MATLAB不同。</p>
<h2 id="梯度下降法-Gradient-Descent"><a href="#梯度下降法-Gradient-Descent" class="headerlink" title="梯度下降法(Gradient Descent)"></a>梯度下降法(Gradient Descent)</h2><p>$$repeat\quad until\quad convergence { \quad<br>\theta_j:=\theta_j-\alpha \frac{\partial J(\theta_0, \theta_1)}{\partial \theta_j} \quad (j=0,1) \quad }$$<br>$\alpha$ : learning rate.<br>$\partial$ : 偏微分</p>
<p>以下为MATLAB实现：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta, J_history]</span> = <span class="title">gradientDescent</span><span class="params">(X, y, theta, alpha, num_iters)</span></span></div><div class="line">	<span class="comment">%GRADIENTDESCENT Performs gradient descent to learn theta</span></div><div class="line">	<span class="comment">%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by </span></div><div class="line">	<span class="comment">%   taking num_iters gradient steps with learning rate alpha</span></div><div class="line">	</div><div class="line">	m = <span class="built_in">length</span>(y); <span class="comment">% number of training examples</span></div><div class="line">	J_history = <span class="built_in">zeros</span>(num_iters, <span class="number">1</span>);</div><div class="line">	</div><div class="line">	<span class="keyword">for</span> iter = <span class="number">1</span>:num_iters</div><div class="line">	    theta = theta -  X' * (X * theta - y) * (alpha / m);  </div><div class="line">	    J_history(iter) = computeCost(X, y, theta);</div><div class="line">	<span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>以下为Python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientDescent</span><span class="params">(X, y, theta, alpha, num_iters)</span>:</span></div><div class="line">    <span class="string">"""Gradient Descent for (Multivariate) Linear Regression</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    X : np.ndarray, like (49 * 2)</span></div><div class="line"><span class="string">    y : np.ndarray, like (49 * 1)</span></div><div class="line"><span class="string">    theta : np.ndarray, like (49 * 1)</span></div><div class="line"><span class="string">    alpha : learning rate</span></div><div class="line"><span class="string">    num_iters : number of iter</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    tuple(J_history, theta)</span></div><div class="line"><span class="string">    J_history : np.ndarray, like (num_iters, 1)</span></div><div class="line"><span class="string">    theta : theta of convergence, like (2 * 1)</span></div><div class="line"><span class="string">    """</span></div><div class="line">    </div><div class="line">    J_history = np.zeros((num_iters, <span class="number">1</span>))</div><div class="line">    <span class="keyword">for</span> n_iter <span class="keyword">in</span> range(num_iters):</div><div class="line">        theta = theta - np.dot(X.T, np.dot(X, theta) - y.reshape(len(y),<span class="number">1</span>)) *alpha / len(y)</div><div class="line">        J_history[n_iter, <span class="number">0</span>] = computeCost(X, y, theta)</div><div class="line">    <span class="keyword">return</span> J_history, theta</div></pre></td></tr></table></figure>
<h2 id="线性回归中的梯度下降公式"><a href="#线性回归中的梯度下降公式" class="headerlink" title="线性回归中的梯度下降公式"></a>线性回归中的梯度下降公式</h2><p>$$\theta_0:= \theta<em>0-\alpha\frac{1}{m} \sum</em>{i=1}^m(h_\theta(x^{(i)})-y^{(i)})$$<br>$$\theta_1:= \theta<em>1-\alpha\frac{1}{m}\sum</em>{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_1^{(i)}$$<br>同理可得：<br>$$\theta_j:= \theta<em>j-\alpha\frac{1}{m}\sum</em>{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$<br>在（多元）线性回归中，由于在代码中直接使用矩阵进行运算，因此代码同上。</p>

  </div>
</article>



    </div>
    
      <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="http://github.com/twostarxx">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#成本函数-Cost-Function"><span class="toc-number">1.</span> <span class="toc-text">成本函数(Cost Function)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度下降法-Gradient-Descent"><span class="toc-number">2.</span> <span class="toc-text">梯度下降法(Gradient Descent)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归中的梯度下降公式"><span class="toc-number">3.</span> <span class="toc-text">线性回归中的梯度下降公式</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/"><i class="fa fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&text=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&is_video=false&description=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Cost Function的原理及实现(Python, Matlab)&body=Check out this article: http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/"><i class="fa fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&title=Cost Function的原理及实现(Python, Matlab)"><i class="fa fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://twostarxx.github.io/2017/11/18/Cost-Function的原理及实现-Python-Matlab/&name=Cost Function的原理及实现(Python, Matlab)&description="><i class="fa fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
      <ul>
        <li id="toc"><a class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa fa-list fa-lg" aria-hidden="true"></i> TOC</a></li>
        <li id="share"><a class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa fa-share-alt fa-lg" aria-hidden="true"></i> Share</a></li>
        <li id="top" style="display:none"><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a></li>
        <li id="menu"><a class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa fa-bars fa-lg" aria-hidden="true"></i> Menu</a></li>
      </ul>
    </div>

  </div>
</div>

    
    <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2017 XingXin
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="http://github.com/twostarxx">Projects</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

</body>
</html>
<!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
<link rel="stylesheet" href="/lib/meslo-LG/styles.css">
<link rel="stylesheet" href="/lib/justified-gallery/justifiedGallery.min.css">

<!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-86660611-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Disqus Comments -->


